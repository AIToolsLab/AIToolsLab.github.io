---

import Layout from '../layouts/Layout.astro';

const publications = [
  {
    title: "Interaction-Required Suggestions for Control, Ownership, and Awareness in Human-AI Co-Writing",
    url: "https://arxiv.org/abs/2504.08726",
    image: "/pubs/interaction-required/type_assistant_response.png",
    imageAlt: "A predictive-text interaction UI where the user types the assistant's response to a revision request",
    authors: ["Kenneth C. Arnold", "Jiho Kim"],
    venue: "Proceedings of the The Fourth Workshop on Intelligent and Interactive Writing Assistants (In2Writing), NAACL 2025",
    date: "May 4, 2025",
    tags: ["HCI", "NLP", "Undergrad"],
    description: `This paper explores interaction designs for generative AI interfaces that necessitate human involvement throughout the generation process. We argue that such interfaces can promote cognitive engagement, agency, and thoughtful decision-making. Through a case study in text revision, we present and analyze two interaction techniques: (1) using a predictive-text interaction to type the assistant's response to a revision request, and (2) highlighting potential edit opportunities in a document. Our implementations demonstrate how these approaches reveal the landscape of writing possibilities and enable fine-grained control. We discuss implications for human-AI writing partnerships and future interaction design directions.`,
    links: [
      { label: "ðŸ“„ Paper", url: "https://arxiv.org/abs/2504.08726", color: "bg-blue-600 hover:bg-blue-700" }
    ]
  },
  {
    title: "Voice Interaction with Conversational AI Could Facilitate Thoughtful Reflection and Substantive Revision in Writing",
    url: "https://arxiv.org/abs/2504.08687",
    image: "",
    imageAlt: "",
    authors: ["Jiho Kim", "Philippe Laban", "Xiang 'Anthony' Chen", "Kenneth C. Arnold"],
    venue: "Proceedings of the The Fourth Workshop on Intelligent and Interactive Writing Assistants (In2Writing), NAACL 2025",
    date: "May 4, 2025",
    tags: ["HCI", "NLP", "Undergrad"],
    description: `Writing well requires not only expressing ideas but also refining them through revision, a process facilitated by reflection. Prior research suggests that feedback delivered through dialogues, such as those in writing center tutoring sessions, can help writers reflect more thoughtfully on their work compared to static feedback. Recent advancements in multi-modal large language models (LLMs) now offer new possibilities for supporting interactive and expressive voice-based reflection in writing. In particular, we propose that LLM-generated static feedback can be repurposed as conversation starters, allowing writers to seek clarification, request examples, and ask follow-up questions, thereby fostering deeper reflection on their writing. We argue that voice-based interaction can naturally facilitate this conversational exchange, encouraging writers' engagement with higher-order concerns, facilitating iterative refinement of their reflections, and reduce cognitive load compared to text-based interactions. To investigate these effects, we propose a formative study exploring how text vs. voice input influence writers' reflection and subsequent revisions. Findings from this study will inform the design of intelligent and interactive writing tools, offering insights into how voice-based interactions with LLM-powered conversational agents can support reflection and revision.`,
    links: [
      { label: "ðŸ“„ Paper", url: "https://arxiv.org/abs/2504.08687", color: "bg-blue-600 hover:bg-blue-700" }
    ]
  },
  {
    title: "Towards Full Authorship with AI: Supporting Revision with AI-Generated Views",
    url: "https://arxiv.org/abs/2403.01055",
    image: "/pubs/haigen24/featured.png",
    imageAlt: "Textfocals UI showing AI-generated views in sidebar",
    authors: ["Jiho Kim", "Ray C. Flanagan", "Noelle E. Haviland", "ZeAi Sun", "Souad N. Yakubu", "Edom A. Maru", "Kenneth C. Arnold"],
    venue: "HAI-GEN Workshop at ACM IUI 2024",
    date: "March 18, 2024",
    tags: ["HCI", "NLP", "Undergrad"],
    description: `We introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice in a sidebar, encouraging reflection and self-driven revision while maintaining full authorship.A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing.`,
    links: [
      { label: "ðŸ“„ Paper", url: "https://arxiv.org/abs/2403.01055", color: "bg-blue-600 hover:bg-blue-700" },
      { label: "ðŸ“Š Poster", url: "/pubs/haigen24/Arnold-Kim-Poster2023.pdf", color: "bg-gray-600 hover:bg-gray-700" }
    ]
  },
  {
    title: "Promoting End-to-End Intentionality with Large Language Models",
    url: "/pubs/cognitive-engagement/poster-summer2024.pdf",
    image: "/pubs/cognitive-engagement/featured.png",
    imageAlt: "Research diagram showing cognitive engagement with AI suggestions",
    authors: ["Jason Chew", "Daniel Kim", "Jiho Kim", "Ray Flanagan", "Kenneth C. Arnold"],
    venue: "Calvin STEM Poster Fair",
    date: "October 25, 2024",
    tags: ["HCI", "NLP", "Undergrad"],
    description: `In Summer 2024, our team of undergraduate students conducted a study on how the type of information suggested by an AI writing assistant affects writersâ€™ cognitive engagement with the suggestion and how they appropriate that suggestion in their draft. We developed a Microsoft Word sidebar  that offered next-sentence suggestions expressed in four different ways: in addition to predictive-text-style examples they could use verbatim (e.g., by copy-and-paste), we also allowed writers to request questions that the next sentence might answer, vocabulary they might use, and rhetorical moves (such as giving examples or considering counterarguments) that their next sentence might engage with.<br><br>In a pilot study (N=8), writers found questions and rhetorical moves to be useful and friendly. Although writers chose to request examples more often, they often rejected the suggested text. Overall, they rated the Questions suggestion type as most compelling in post-task surveys, followed by Examples. These preliminary results suggest that writers welcomed AI suggestions that could not be inserted verbatim into their documents but instead required further thought. Overall, by offering intentionally-incomplete suggestions like Questions or Rhetorical Moves, AI systems might become better cognitive partners for writers, enriching thinking rather than circumventing it. This work has been presented at an internal poster fair; we are designing a follow-up experiment to build on these findings for broader publication.`,
    links: [
      { label: "ðŸ“Š Poster", url: "/pubs/cognitive-engagement/poster-summer2024.pdf", color: "bg-gray-600 hover:bg-gray-700" }
    ]
  }
];
---

<Layout title="Publications" metaDescription="Research publications from the Thoughtful AI Tools Lab at Calvin University">
  <main>
    <section class="px-8 py-20 mx-auto max-w-screen-xl">
      <div class="container mx-auto">
        <h1 class="text-5xl font-bold text-center mb-12 text-blue-gray-900">Publications</h1>
        
        <div class="grid gap-8 lg:grid-cols-1 xl:grid-cols-1">
          {publications.map((pub) => (
            <div class="bg-white rounded-lg shadow-lg border border-gray-200 overflow-hidden">
              <div class="flex flex-col lg:flex-row">
                <div class="lg:w-1/3 relative group cursor-pointer" onclick={`openImageModal('${pub.image}', '${pub.imageAlt}')`}>
                  <img src={pub.image} alt={pub.imageAlt} class="w-full h-48 lg:h-full object-cover transition-transform duration-300 group-hover:scale-105" />
                  <div class="absolute inset-0 bg-black bg-opacity-0 group-hover:bg-opacity-20 transition-all duration-300 flex items-center justify-center">
                    <div class="text-white opacity-0 group-hover:opacity-100 transition-opacity duration-300 text-sm font-medium">
                      Click to expand
                    </div>
                  </div>
                </div>
                <div class="lg:w-2/3 p-6">
                  <h3 class="text-xl font-semibold mb-2 text-blue-gray-900">
                    {pub.url ? (
                      <a href={pub.url} target="_blank" class="hover:text-blue-500 transition-colors">{pub.title}</a>
                    ) : (
                      pub.title
                    )}
                  </h3>
                  <p class="text-gray-600 mb-3">Authors: {pub.authors.join(", ")}</p>
                  <p class="text-gray-600 mb-3 text-sm">{pub.venue}{pub.date ? ` â€¢ ${pub.date}` : ''}</p>
                  <div class="flex flex-wrap gap-2 mb-3">
                    {pub.tags.map(tag => (
                      <span class={`px-2 py-1 rounded-full text-sm ${tag === 'HCI' ? 'bg-blue-100 text-blue-800' : tag === 'NLP' ? 'bg-green-100 text-green-800' : 'bg-purple-100 text-purple-800'}`}>{tag}</span>
                    ))}
                  </div>
                  <p class="text-gray-700 mb-4" set:html={pub.description}></p>
                  <div class="flex gap-3">
                    {pub.links.map(link => (
                      <a href={link.url} target="_blank" class={`inline-flex items-center px-3 py-1 ${link.color} text-white text-sm rounded transition-colors`}>
                        {link.label}
                      </a>
                    ))}
                  </div>
                </div>
              </div>
            </div>
          ))}
        </div>
      </div>
    </section>
    
    
  </main>

  <!-- Image Modal -->
  <div id="imageModal" class="fixed inset-0 bg-black bg-opacity-75 z-50 hidden flex items-center justify-center p-0 w-full h-full overflow-auto" onclick="closeImageModal()">
    <div class="relative w-full h-full flex items-center justify-center">
      <img id="modalImage" src="" alt="" class="object-contain rounded-lg max-w-[95vw] max-h-[90vh] w-auto h-auto mx-auto my-auto">
      <button 
        onclick="closeImageModal()" 
        class="absolute top-4 right-4 text-white bg-black bg-opacity-50 rounded-full w-8 h-8 flex items-center justify-center hover:bg-opacity-75 transition-all"
      >
        âœ•
      </button>
    </div>
  </div>

  <script>
    window.openImageModal = function(imageSrc, altText) {
      const modal = document.getElementById('imageModal');
      const modalImage = document.getElementById('modalImage') as HTMLImageElement;
      if (!modalImage) return; // Ensure modalImage exists
      modalImage.src = imageSrc;
      modalImage.alt = altText;
      modal.classList.remove('hidden');
      document.body.style.overflow = 'hidden';
    }

    window.closeImageModal = function() {
      const modal = document.getElementById('imageModal') as HTMLDivElement;
      if (!modal) return; // Ensure modal exists
      modal.classList.add('hidden');
      document.body.style.overflow = 'auto';
    }

    // Close modal on escape key
    document.addEventListener('keydown', function(e) {
      if (e.key === 'Escape') {
        window.closeImageModal();
      }
    });
  </script>
</Layout>
