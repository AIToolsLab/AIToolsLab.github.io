[
  {
    "objectID": "pubs/haigen24/index.html",
    "href": "pubs/haigen24/index.html",
    "title": "Towards Full Authorship with AI: Supporting Revision with AI-Generated Views",
    "section": "",
    "text": "Important\n\n\n\nNote: all other authors are undergraduate students\nPDF presented at HAI-GEN 2024\nWant to know more or try it out? Sign up here!\nPreviously presented as a poster at 2023 West Michigan Regional Undergraduate Science Research Conference and Calvin University Summer Research Poster Fair, 2023"
  },
  {
    "objectID": "pubs/haigen24/index.html#abstract",
    "href": "pubs/haigen24/index.html#abstract",
    "title": "Towards Full Authorship with AI: Supporting Revision with AI-Generated Views",
    "section": "Abstract",
    "text": "Abstract\nLarge language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user’s authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user’s role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals’ UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity."
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Promoting End-to-End Intentionality with Large Language Models\n\n\n\n\n\n\nHCI\n\n\nNLP\n\n\nUndergrad\n\n\n\n\n\n\n\n\n\nOct 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Full Authorship with AI: Supporting Revision with AI-Generated Views\n\n\n\n\n\n\nHCI\n\n\nNLP\n\n\nUndergrad\n\n\n\n Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user’s authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user’s role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals’ UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity. \n\n\n\n\n\nMar 18, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thoughtful AI Tools Lab",
    "section": "",
    "text": "We are a research group at Calvin University focused on how AI can help people think better.\nContributing to a flourishing world requires thought.\nWe build AI tools to support sustained goal-directed cognitive effort despite unclear goals and complex situations."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "pubs/cognitive-engagement/index.html",
    "href": "pubs/cognitive-engagement/index.html",
    "title": "Promoting End-to-End Intentionality with Large Language Models",
    "section": "",
    "text": "Poster presented at 2024 Calvin University Summer Research Poster Fair.\nIn Summer 2024, our team of undergraduate students conducted a study on how the type of information suggested by an AI writing assistant affects writers’ cognitive engagement with the suggestion and how they appropriate that suggestion in their draft. We developed a Microsoft Word sidebar that offered next-sentence suggestions expressed in four different ways: in addition to predictive-text-style examples they could use verbatim (e.g., by copy-and-paste), we also allowed writers to request questions that the next sentence might answer, vocabulary they might use, and rhetorical moves (such as giving examples or considering counterarguments) that their next sentence might engage with.\nIn a pilot study (N=8), writers found questions and rhetorical moves to be useful and friendly. Although writers chose to request examples more often, they often rejected the suggested text. Overall, they rated the Questions suggestion type as most compelling in post-task surveys, followed by Examples. These preliminary results suggest that writers welcomed AI suggestions that could not be inserted verbatim into their documents but instead required further thought. Overall, by offering intentionally-incomplete suggestions like Questions or Rhetorical Moves, AI systems might become better cognitive partners for writers, enriching thinking rather than circumventing it. This work has been presented at an internal poster fair; we are designing a follow-up experiment to build on these findings for broader publication."
  }
]